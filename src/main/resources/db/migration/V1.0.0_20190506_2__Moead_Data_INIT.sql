INSERT INTO `algorithmic` VALUES (1,'MOEAD多目标算法','## 多目标进化算法(MOEA)概述\n\n- [多目标优化]() \n\n- [进化计算]() \n- [Pareto支配]() \n- [基于分解方法]() \n\n对于大多数多目标优化问题，其各个目标往往是相互冲突的，因此不可能使得所有的目标同时达到最优，而是一组各个目标值所折衷的解集，称之为Pareto最优集。以下为一些基本定义(以最小化优化问题为例)：\n\n#### Definition 1: 多目标优化问题(multi-objective optimization problem(MOP)) \n\n$$\nF(x)=(f1(x),…,fm(x))s.t.x∈Ω\n$$\n\n#### Definition 2: Pareto支配(Pareto Dominance) \n\n$$\nx支配y,记为 x ≺ y ，当且仅当∀i∈{1,2,...,m},fi(x)≤fi(y), 且∃j∈{1,2,...,m}, s.t.fj(x)<fj(y) \n$$\n\n#### Definition 3: Pareto最优解(Pareto Optimal Solution) \n\n$$\n如果一个解x∗ 被称之为Pareto optimal solution， 当且仅当 x∗ 不被其他的解支配。\n$$\n\n#### Definition 4: Pareto 集(Pareto Set) \n\n一个MOP，对于一组给定的最优解集，如果这个集合中的解是相互非支配的，也即两两不是支配关系，那么则称这个解集为Pareto Set 。\n\n#### Definition 5: Pareto 前沿(Pareto Front) \n\nPareto Set 中每个解对应的目标值向量组成的集合称之为Pareto Front, 简称为PF\n\n#### Definition 6：近似集(Approximation Set) \n\n一般来说，准确的Pareto Set是很难得到的，其近似集相比来说容易得到，因此一般我们只需用一定数量的Approximation Set 来表示PS 。\n\n#### Definition 7： 近似前沿(Approximation Front) \n\nApproximation Set 中每个解对应的目标值向量组成的集合称之为Approximation Front 。\n目前来说，由于多目标问题的复杂性，传统的数学方法不能取得较为理想的结果，而进化算法在多目标优化问题上得到了很广泛的应用，通过种群的不断进化迭代，进化算法能得到一个Approximation Set，那么我们如何来评价得到的Approximation Set的优劣呢，以下为两方面的评价标准。 \n\n#### Definition 7：收敛性(Convergence) \n\nApproximation Front 与 PF 的贴近程度。\n\n#### Definition 8: 分布性(Distribution) \n\n描述Approximation Front 在PF 的分布情况，包括多样性(Diversity)和均匀性(Uniformity)。\n具体来说，常用的两个指标分别是IGD(Inverted Generational Distance) 和 HV(Hypervolume)。其中，IGD需要知道PF数据，且其具体计算为每个PF中的点到其最近的Approximation Front中的点的距离之和的均值。同时，需注意，这两种方法都能同时度量解的分布性和收敛性。\n现在来讲讲主流的多目标进化算法。 \n从进化算法的角度来讲，目前已有遗传算法(GA)，粒子群算法(PSO)，蚁群算法(ACO)等一系列算法用来解决多目标优化问题，但用的比较多的还是遗传算法，粒子群算法也有。 \n从多目标问题本身来说，主要分类如下： \n\n- 基于Pareto支配关系 \n\n- 基于分解的方法 \n\n- 基于Indicator方法\n\n先来介绍下基于遗传算法的多目标优化算法的一些基本参数： \n​      种群大小：每次迭代都需保证种群大小是一致的，且其大小应由初始化设定。 \n​      交叉概率：用于衡量两个个体交叉的概率。 \n​      突变率：交叉产生的解发生突变的概率。 \n​      标准的遗传算法每次迭代都会将上一代的个体丢弃，虽然这符合自然规律，但对于遗传算法来说，这样效果不是特别好，因此，精英保留策略将上一代个体和当前个体混合竞争产生下一代，这种机制能较好的保留精英个体。 \n  **基于Pareto支配关系** \n  最经典的方法是NSGA-II，该方法由Kalyanmoy Deb等人于2002年提出(A Fast and Elitist Multiobjective Genetic Algorithm: \n  NSGA-II)，该方法主要包括快速非支配排序，将每次交叉突变产生的解和前一代的解合并，然后利用非支配排序分层，其伪代码如下：\n\n![](/images/algorithmic/001.png)\n\n再就是把每层相加直到超过种群个体，再在最后一层基于拥挤距离来选择解，拥挤距离伪代码如下： \n\n![](/images/algorithmic/002.png)\n\n具体来说，NSGA-II使用快速非支配排序来保证收敛性，并且利用拥挤距离来保证分布性。特别说下，在迭代后期，大多数解都是非支配的，也即大多数解都在第一层。 \n当然，随着NSGA-II的提出，很多基于此的算法如雨后春笋般大量涌现，特别是在处理高维多目标优化问题时这种想法得到很多的应用，如VaEA，RVEA，NSGA-III等。 \n同时，SPEA2也是基于Pareto支配关系的一种较为流行的算法(SPEA2: Improving the Strength Pareto Evolutionary Algorithm)，该算法使用一个外部保存集来保存较为优秀的解，同时，对每一个解，利用其支配的解的数量和基于KNN的邻近解的距离来给每一个解打分，得分越小的解更优。\n**基于分解的方法** \n该方法第一次系统地被提出是在2007年由Qingfu Zhang等人提出(MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition)，该方法将MOP分解为多个子问题，这样就可以优化每个子问题来求解一个MOP。一般而言，基于分解的方法首先需要得到一组均匀分布的参照向量来指导选择操作。在此，有必要说说产生参照向量的方法。目前对于低维多目标优化问题，常用方法为Das and Dennis于1998年提出的systematic approach(Normal-boundary intersection: A new method for generating the pareto surface in nonlinear multicriteria optimization problems). \n对于每个参照向量，其指导选择的过程需要比较解的优劣，这就需要用到一些标量函数来定量衡量一个解对于这个参照向量的适应度值。常用的标量函数包括： \n\n- Weighted Sum Approach \n\n- Tchebycheff Approach \n\n- penalty-based boundary intersection (PBI) approach\n  **Weighted Sum Approach** \n  $$\n  mingws(x|λ)=∑mi=1λifi(x)\n  $$\n  其中λ是参照向量，其运行机理如下图：\n\n  ![](/images/algorithmic/003.png)\n\n  其中λ是参照向量，其运行机理如下图：\n\n这里需要注意，标准的Weighted Sum Approach不能处理非凸问题，因为由上图可知，对于非凸问题，每个参照向量的垂线与其前沿不可能相切。对于这个问题，Rui Wang等人与2016年提出相对应的改进(Localized weighted sum method for many-objective optimization)，主要是约束替换范围。\n**Tchebycheff Approach **\n$$\nmingte(x|λ,z∗)=max{λi(fi(x)−z∗i)}\n$$\n其中λ是参照向量，其运行机理如下图： \n\n其中λ是参照向量，其运行机理如下图： \n\n![](/images/algorithmic/004.png)\n\n标准的Tchebycheff Approach得到的解不均匀，为此Yutao Qi等人于2014年提出一种解决方法(MOEA/D with Adaptive Weight Adjustment)，λ∗=(1λ1∑mi=11λi,....,1λm∑mi=11λi),通过这个参照向量的转换即可得到分布均匀的解。\n**penalty-based boundary intersection (PBI) approach **\n$$\nmingpbi(x|λ,z∗)=d1+θd2\n$$\n![](/images/algorithmic/005.png)\n\n\n\n其中d1，d2如上图所示。一般来说，θ=5是比较常用的，Yuan Yuan等人提出的θ−DEA算法对θ的取值有较为详细的讨论(A New Dominance Relation-Based Evolutionary Algorithm for Many-Objective Optimization)。 \n\n基于分解的进化方法框架如下： \n\n![](/images/algorithmic/006.png)\n\n**基于Indicator方法 **\n相比于IGD指标，Hypervolume更容易用来作为一个测度在种群进化过程中用来选择个体,如IBEA[8]以及其快速计算HV的HypE[9]，因为IGD需要知道真实的Pareto Front数据，而这对于一个未知多目标优化问题是相当困难的，但有些算法是用当前的非支配解来近似Pareto Front，如AR-MOEA[10]。\n论文中常用的测试问题及其Pareto前沿可参考多目标优化问题','2019-05-09 14:05:48','2019-05-06 15:39:48',3);


INSERT INTO `user` VALUES (1,1001,'admin',1,'男','12285412358','123456','jia@126.com',0,'2019-05-06'),(2,1002,'student',21,'女','12285412358','123456','jia@126.com',1,'2019-05-06'),(3,1003,'teacher',NULL,'女','12285412358','123456','jia@126.com',2,'2019-05-06');
